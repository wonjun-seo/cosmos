{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3799c0",
   "metadata": {},
   "source": [
    "# Potential Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be3c0",
   "metadata": {},
   "source": [
    "\n",
    "We will use the [potential outcome framework](https://en.wikipedia.org/wiki/Rubin_causal_model) in this note. There are many other approaches including the [direct acyclic graphs](https://en.wikipedia.org/wiki/Causal_graph).\n",
    "\n",
    "Suppose we **observe** a data set with treatment $Z_i$ ($A$ or $B$) and outcome $Y_i$ (1 for success and 0 for fail) for $i=1,2,\\ldots, n$. Further consider the **potential outcomes** $Y_i( \\text{treatment} = A)$ that represents the outcome if subject $i$ receives treatment $A$, and $Y_i( \\text{treatment} = B)$,  the outcome if subject $i$ receives treatment $B$. Using the notation of potential outcomes, we can write the observed outcome as $Y_i(Z_i)$, which shows that only one potential outcome is observed for each unit. The following table show the potential outcomes and the **observed values** in orange. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec9072a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94053d9069aa4eeeaa6d230f0bc34a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<b>Potential-outcome playground</b><br>Choose <i>one</i> cell per column.<br><span …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np, ipywidgets as wd\n",
    "from scipy.stats import ttest_ind\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# ------------------------------------------------------------------ data ----\n",
    "rng      = np.random.default_rng(2)\n",
    "n_subj   = 10\n",
    "Y0 = rng.normal(70, 10, n_subj)                 # potential control outcomes\n",
    "Y1 = Y0 + rng.normal(0, 3,  n_subj)             # potential treatment outcomes\n",
    "\n",
    "# ----- containers -----------------------------------------------------------\n",
    "selected  = [None]*n_subj       # None / 0 / 1\n",
    "observed  = [None]*n_subj\n",
    "\n",
    "out = wd.Output()\n",
    "\n",
    "def reset_state():\n",
    "    \"\"\"Clear selections & visuals.\"\"\"\n",
    "    for c in range(n_subj):\n",
    "        selected[c] = None\n",
    "        observed[c] = None\n",
    "        for r in range(2):\n",
    "            btn = buttons[r][c]\n",
    "            btn.disabled = False\n",
    "            btn.style.button_color = None\n",
    "    with out: clear_output()\n",
    "\n",
    "# ----------------- statistic & display --------------------------------------\n",
    "def show_results():\n",
    "    treat   = [v for s,v in zip(selected, observed) if s == 1]\n",
    "    control = [v for s,v in zip(selected, observed) if s == 0]\n",
    "    diff    = np.mean(control) - np.mean(treat)\n",
    "    t_stat, p_val = ttest_ind(control, treat, equal_var=False)\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(\"----- Results -----\")\n",
    "        print(f\"Control mean = {np.mean(control):.2f}\")\n",
    "        print(f\"Treat   mean = {np.mean(treat):.2f}\")\n",
    "        print(f\"Mean diff (C − T) = {diff:.2f}\")\n",
    "        print(f\"Welch t = {t_stat:.3f}\")\n",
    "        print(f\"p-value = {p_val:.3f}\")\n",
    "\n",
    "# ----------------- button factory -------------------------------------------\n",
    "def make_button(row, col):\n",
    "    val = Y0[col] if row == 0 else Y1[col]\n",
    "    b = wd.Button(description=f\"{val:.1f}\",\n",
    "                  layout=wd.Layout(width=\"65px\"),\n",
    "                  tooltip=f\"Subj {col+1} | Y{row}\")\n",
    "    def on_click(_):\n",
    "        if selected[col] is not None: return\n",
    "        selected[col] = row\n",
    "        observed[col] = val\n",
    "        # visual updates\n",
    "        for r in range(2):\n",
    "            buttons[r][col].disabled = True\n",
    "        b.style.button_color = \"orange\"\n",
    "        if None not in selected:\n",
    "            show_results()\n",
    "    b.on_click(on_click)\n",
    "    return b\n",
    "\n",
    "# ----------------- build grid -----------------------------------------------\n",
    "buttons = [[make_button(r,c) for c in range(n_subj)] for r in range(2)]\n",
    "grid = wd.VBox([wd.HBox(buttons[0]), wd.HBox(buttons[1])])\n",
    "\n",
    "# ----------------- randomize logic ------------------------------------------\n",
    "def randomize(_):\n",
    "    reset_state()\n",
    "    idx = rng.permutation(n_subj)\n",
    "    ctrl_cols, treat_cols = idx[:5], idx[5:]\n",
    "    # programmatic \"click\"\n",
    "    for c in ctrl_cols:\n",
    "        buttons[0][c].click()\n",
    "    for c in treat_cols:\n",
    "        buttons[1][c].click()\n",
    "\n",
    "rand_btn  = wd.Button(description=\"Randomize assignment\",\n",
    "                      button_style='success')\n",
    "rand_btn.on_click(randomize)\n",
    "\n",
    "reset_btn = wd.Button(description=\"Reset\", button_style='warning')\n",
    "reset_btn.on_click(lambda _: reset_state())\n",
    "\n",
    "# ----------------- assemble UI ----------------------------------------------\n",
    "header = wd.HTML(\n",
    "    \"<b>Potential-outcome playground</b><br>\"\n",
    "    \"Choose <i>one</i> cell per column.<br>\"\n",
    "    \"<span style='color:blue'>Top</span> = control Y₀,&nbsp;\"\n",
    "    \"<span style='color:blue'>bottom</span> = treatment Y₁.\"\n",
    ")\n",
    "\n",
    "ui = wd.VBox([header, grid, wd.HBox([rand_btn, reset_btn]), out])\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915920c",
   "metadata": {},
   "source": [
    "\n",
    "With these new notations, we can see that the what-ifs describe the comparison of potential outcomes, e.g., $Y_i(A)-Y_i(B)$. To be specific, a causal effect is  defined to be the comparison of the  potential outcomes on the **same units**.\n",
    "- **Individual causal effect**:  $Y_i(A)-Y_i(B)$.\n",
    "- **Average causal effect** (ACE): $\\text{mean}\\{Y_i(A)-Y_i(B)\\}$\n",
    "\n",
    "It is important to notice that $\\text{mean}\\{Y_i(A)\\}$ does not equal to $\\text{mean}\\{Y_i \\mid Z_i=A\\} $ in general. We can see this using the examples in the above tables.\n",
    "- $\\text{mean}\\{Y_i(A)\\}$: average of $Y_i(A)$ for units 1, 2, 3, 4.\n",
    "- $\\text{mean}\\{Y_i\\mid Z_i=A\\}$: average of $Y_i$ for units 1,3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37874122",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The above tables also reveal the fundamental problem of causal inference. That is only one potential outcome is observed.  In randomized experiments, randomization ensures $\\text{mean}\\{Y_i(A)\\} = \\text{mean}\\{Y_i \\mid Z_i=A\\} $, which allows us to estimate the average causal effects. We should always think about what can and what cannot be learned from the observed data.\n",
    "\n",
    "> If your experiment needs statistics, you ought to have done a better experiment.\n",
    ">\n",
    ">        --  Ernest Rutherford \n",
    "        \n",
    "\n",
    "> Regression models often seem to be used to compensate for problems in measurement, data collection, and study design. By the time models are deployed, the scientific position is nearly hopeless. \n",
    "> \n",
    ">        --  David Freedman \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70578864",
   "metadata": {},
   "source": [
    "### Identification and Randomization  \n",
    "\n",
    "A new task that will be often discussed in this chapter is **Identification**: what can be identified if there are infinite amount of data. This tasks concerns the design of experiements or how the data is collected. In contrast, the **Inference** problem, where we study what can be learned given a finite sample, is what we have focused on in most of the statistical methods. \n",
    "\n",
    "We can now examine why causal interpretation is possible from randomized experiments. Recall that the average treatment effect is defined as  \n",
    "$$\n",
    "{\\rm ACE} \\equiv \\mathbb{E}[Y(1)-Y(0)]=\\mathbb{E}[Y(1)]-\\mathbb{E}[Y(0)].\n",
    "$$\n",
    "**Randomization of treatments means $\\{Z_i\\}_{i=1}^n \\perp \\{ Y_i(0), Y_i(1)\\}_{i=1}^n$.**\n",
    "\n",
    "We can derive \n",
    "\\begin{align}\n",
    "{\\rm ACE} & = \\mathbb{E}[Y(1)]-\\mathbb{E}[Y(0)]=\\mathbb{E}[Y(1)|Z=1]-\\mathbb{E}[Y(0)|Z=0]\\\\\n",
    "& = \\mathbb{E}[Y|Z=1]-\\mathbb{E}[Y|Z=0],\n",
    "\\end{align}\n",
    "where the second equality follows from independence between treatments and potential outcomes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
